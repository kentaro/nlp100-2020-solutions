{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第1章: 準備運動\n",
    "\n",
    "https://nlp100.github.io/ja/ch01.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 00. 文字列の逆順"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "文字列”stressed”の文字を逆に（末尾から先頭に向かって）並べた文字列を得よ．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 解答1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "スライスで、最後の文字からとっていく例。`[start:stop:step]`なので、startとstopを省略して、stepに`-1`を指定すると、後ろから一個ずつとっていく。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'desserts'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"stressed\"[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 解答2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`reversed`で逆順にしたイテレータを作ったものをlistにしてから空文字でjoinする。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\".join(list(reversed(\"stressed\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01. 「パタトクカシーー」"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "「パタトクカシーー」という文字列の1,3,5,7文字目を取り出して連結した文字列を得よ．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 解答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'パトカー'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"パタトクカシーー\"[::2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03. 円周率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "“Now I need a drink, alcoholic of course, after the heavy lectures involving quantum mechanics.”という文を単語に分解し，各単語の（アルファベットの）文字数を先頭から出現順に並べたリストを作成せよ．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 解答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'after',\n",
       " 'alcoholic',\n",
       " 'course',\n",
       " 'drink',\n",
       " 'heavy',\n",
       " 'I',\n",
       " 'involving',\n",
       " 'lectures',\n",
       " 'mechanics',\n",
       " 'need',\n",
       " 'Now',\n",
       " 'of',\n",
       " 'quantum',\n",
       " 'the']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "s = re.sub(\"[,.]\", \"\", \"Now I need a drink, alcoholic of course, after the heavy lectures involving quantum mechanics.\")\n",
    "sorted(s.split(), key=str.lower)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04. 元素記号"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "“Hi He Lied Because Boron Could Not Oxidize Fluorine. New Nations Might Also Sign Peace Security Clause. Arthur King Can.”という文を単語に分解し，1, 5, 6, 7, 8, 9, 15, 16, 19番目の単語は先頭の1文字，それ以外の単語は先頭に2文字を取り出し，取り出した文字列から単語の位置（先頭から何番目の単語か）への連想配列（辞書型もしくはマップ型）を作成せよ．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 解答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'H': 1,\n",
       " 'He': 2,\n",
       " 'Li': 3,\n",
       " 'Be': 4,\n",
       " 'B': 5,\n",
       " 'C': 6,\n",
       " 'N': 7,\n",
       " 'O': 8,\n",
       " 'F': 9,\n",
       " 'Ne': 10,\n",
       " 'Na': 11,\n",
       " 'Mi': 12,\n",
       " 'Al': 13,\n",
       " 'Si': 14,\n",
       " 'P': 15,\n",
       " 'S': 16,\n",
       " 'Cl': 17,\n",
       " 'Ar': 18,\n",
       " 'K': 19,\n",
       " 'Ca': 20}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans   = {}\n",
    "idxes = [1, 5, 6, 7, 8, 9, 15, 16, 19]\n",
    "words = \"Hi He Lied Because Boron Could Not Oxidize Fluorine. New Nations Might Also Sign Peace Security Clause. Arthur King Can.\".strip(\".\").split()\n",
    "\n",
    "for i, w in enumerate(words):\n",
    "    if i + 1 in idxes:\n",
    "        ans[w[:1]] = i + 1\n",
    "    else:\n",
    "        ans[w[:2]] = i + 1\n",
    "\n",
    "ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 05. n-gram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "与えられたシーケンス（文字列やリストなど）からn-gramを作る関数を作成せよ．この関数を用い，”I am an NLPer”という文から単語bi-gram，文字bi-gramを得よ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['I', 'am'], ['an', 'NLPer']]\n",
      "[['I', 'am'], ['an', 'NLPer']]\n",
      "['Ia', 'ma', 'nN', 'LP', 'er']\n",
      "['Ia', 'ma', 'nN', 'LP', 'er']\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def n_gram(n, target):      \n",
    "    return [ target[i*n:i*n+n] for i in range(math.ceil(len(target)/n)) ]\n",
    "\n",
    "def n_gram_by_chars(n, target):\n",
    "    if type(target) is str:\n",
    "        target = target.replace(\" \", \"\")\n",
    "    return n_gram(n, \"\".join(target))\n",
    "\n",
    "def n_gram_by_words(n, target):\n",
    "    if type(target) is str:\n",
    "        target = target.split()\n",
    "    return n_gram(n, target)\n",
    "\n",
    "# 単語bi-gram\n",
    "print(n_gram_by_words(2, \"I am an NLPer\"))\n",
    "print(n_gram_by_words(2, [\"I\", \"am\", \"an\", \"NLPer\"]))\n",
    "\n",
    "# 文字bi-gram\n",
    "print(n_gram_by_chars(2, \"I am an NLPer\"))\n",
    "print(n_gram_by_chars(2, [\"I\", \"am\", \"an\", \"NLPer\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 06. 集合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "“paraparaparadise”と”paragraph”に含まれる文字bi-gramの集合を，それぞれ, XとYとして求め，XとYの和集合，積集合，差集合を求めよ．さらに，’se’というbi-gramがXおよびYに含まれるかどうかを調べよ．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 解答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: {'se', 'di', 'ra', 'pa'}\n",
      "Y: {'gr', 'ra', 'h', 'ap', 'pa'}\n",
      "和集合: {'gr', 'ra', 'h', 'di', 'se', 'ap', 'pa'}\n",
      "積集合: {'ra', 'pa'}\n",
      "差集合: {'se', 'di'}\n",
      "Xにseが含まれるかどうか？: True\n",
      "Yにseが含まれるかどうか？: False\n"
     ]
    }
   ],
   "source": [
    "X = set(n_gram_by_chars(2, \"paraparaparadise\"))\n",
    "Y = set(n_gram_by_chars(2, \"paragraph\"))\n",
    "\n",
    "print(\"X: {}\".format(X))\n",
    "print(\"Y: {}\".format(Y))\n",
    "\n",
    "print(\"和集合: {}\".format(X | Y))\n",
    "print(\"積集合: {}\".format(X & Y))\n",
    "print(\"差集合: {}\".format(X - Y))\n",
    "\n",
    "print(\"Xにseが含まれるかどうか？: {}\".format(\"se\" in X))\n",
    "print(\"Yにseが含まれるかどうか？: {}\".format(\"se\" in Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 07. テンプレートによる文生成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "引数x, y, zを受け取り「x時のyはz」という文字列を返す関数を実装せよ．さらに，x=12, y=”気温”, z=22.4として，実行結果を確認せよ．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 解答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12時の気温は22.4\n"
     ]
    }
   ],
   "source": [
    "def format(x, y, z):\n",
    "    return \"{}時の{}は{}\".format(x, y, z)\n",
    "\n",
    "print(format(12, \"気温\", 22.4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 08. 暗号文"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "与えられた文字列の各文字を，以下の仕様で変換する関数cipherを実装せよ．\n",
    "\n",
    "* 英小文字ならば(219 - 文字コード)の文字に置換\n",
    "* その他の文字はそのまま出力\n",
    "\n",
    "\n",
    "この関数を用い，英語のメッセージを暗号化・復号化せよ．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 解答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'“Hr Hv Lrvw Bvxzfhv Blilm Clfow Nlg Ocrwrav Foflirmv. Nvd Nzgrlmh Mrtsg Aohl Srtm Pvzxv Svxfirgb Cozfhv. Aigsfi Krmt Czm.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def cipher(text):\n",
    "    res = \"\"\n",
    "    for c in text:\n",
    "        if re.match(\"[a-z]\", c):\n",
    "            res += chr(219 - ord(c))\n",
    "        else:\n",
    "            res += c\n",
    "    return res\n",
    "\n",
    "cipher(\"“Hi He Lied Because Boron Could Not Oxidize Fluorine. New Nations Might Also Sign Peace Security Clause. Arthur King Can.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 09. Typoglycemia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "スペースで区切られた単語列に対して，各単語の先頭と末尾の文字は残し，それ以外の文字の順序をランダムに並び替えるプログラムを作成せよ．ただし，長さが４以下の単語は並び替えないこととする．適当な英語の文（例えば”I couldn’t believe that I could actually understand what I was reading : the phenomenal power of the human mind .”）を与え，その実行結果を確認せよ．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 解答 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I cdun’olt beevlie that I cluod alcutaly uatnsrdend what I was rnaeidg : the pneeonahml pweor of the hamun mind.\n",
      "I culo’dnt beelive that I colud aullacty utndnresad what I was rainedg : the pneamhonel pewor of the huamn mind.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import random\n",
    "\n",
    "def randomize(text):\n",
    "    res = []\n",
    "    for w in text.split():\n",
    "        if len(re.sub(\"[.,]\", \"\", w)) <= 4:\n",
    "            res.append(w)\n",
    "        else:\n",
    "            head = w[:1]\n",
    "            tail = w[-1:]\n",
    "            body = list(w[1:-1])\n",
    "            random.shuffle(body)\n",
    "            body = \"\".join(body)\n",
    "            res.append(head + body + tail)\n",
    "    return \" \".join(res)\n",
    "\n",
    "print(randomize(\"I couldn’t believe that I could actually understand what I was reading : the phenomenal power of the human mind.\"))\n",
    "print(randomize(\"I couldn’t believe that I could actually understand what I was reading : the phenomenal power of the human mind.\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
